\documentclass[10pt, a4paper]{report}

\title{Cycling simulation\\or\\\textit{When} to break away?}
\date{\today}
\author{Dan Demeter\and Robert Kruszewski\and Alexandru P\u{a}unoiu \and C\'esar Prout\'e \and Julian Sutherland}


%\setlength\parindent{0pt}
\usepackage{tabularx, alltt, amsmath, multirow, graphicx, url, graphics}

%Our Executive Summary
\renewcommand{\abstractname}{Executive Summary}

% Better looking chapters headings
\usepackage{titlesec}
\titleformat{\chapter}
  {\normalfont\LARGE\bfseries}{\thechapter}{1em}{}
\titlespacing*{\chapter}{0pt}{3.5ex plus 1ex minus .2ex}{2.3ex plus .2ex}


\begin{document}

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page

%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\LARGE Imperial College London}\\[1.5cm] % Name of your university/college
\textsc{\Large Department of Computing}\\[0.5cm] % Major heading such as course name
\textsc{\large}\\[0.5cm] % Minor heading such as course title

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
{ \huge \bfseries Cycling simulation\\or\\\vspace{0.4cm}\textit{When} to break away?}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]

%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Authors:}\\
Dan Demeter \\
Robert Kruszewski\\
Alexandru P\u{a}unoiu\\
C\'esar Prout\'e\\
Julian Sutherland
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Supervisor:} \\
Dr. Panos \textsc{Parpas} % Supervisor's Name
\end{flushright}
\end{minipage}\\[5cm]

% If you don't want a supervisor, uncomment the two lines below and remove the section above
%\Large \emph{Author:}\\
%John \textsc{Smith}\\[3cm] % Your name

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large \today}\\[3cm] % Date, change the \today to a set date if you want to be precise

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

%\includegraphics{Logo}\\[1cm] % Include a department/university logo - this will require the graphicx package

%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with white space
\end{titlepage}

%% Ending of title page

\tableofcontents

\begin{abstract}

%TODO: needs improvement
% CÃ©sar : I think it needs to be more about what we did rather than how cycling works.

Cycling races are amongst one of the most popular sports worldwide. Their history dates back to the
$18^{th}$ century being adopted and since then the types of races spanned substantially: from Track cycling on banks and velodromes,
Cycle-cross, Mountain bike races, one-day road race, criterion or time trial to professional races such as
Tour de France, Giro d'Italia or Vuelta a Espa\~na. During those professional races it is expected that a group of riders break away
from the main group and cooperate with each other in order to gain advantage from the main group ( called peloton ). Riders in such a
group are forced to cooperate with each other, even though their chances of winning are decreasing as more members join the break away
group. Also, when a breakaway group is being formed, riders from the peloton have to decide whether to chase it down or remain where
they are.

During the race, based on their remaining strength, remaining distance until the finish line and other factors riders need to decide
fast their next move. There are famous examples when the rider's hesitation or bad decision costed him the grand title. One notable event might be the 2011 tour de France when Alberto Contador made escapes on during some stages only to be caught by the rest because very few and mostly weak racers escaped with him. [ Will add another relevant and interesting example ]

From our point of view, all these decisions can be modelled by a Game Theory strategy. During our project, we have tried to find optimum strategies that can be applied to various cycling races. We have proposed a Game Theory model based on our research and an independent simulation used to verify our model. We continued the work of [ cite the papers here] and try to obtain a model that is as appropriate as real life cycling races. Using our simulation combined with the game theory model we believe that one should be able to simulate any Professional cycling race. Coaches and racers can use this data then to compare decisions taken  during the race. Our project aims to combine both Game Theory strategies with data from multiple simulated races in order to output 'optimal' decisions

\end{abstract}


\chapter{Introduction}

The first cycling race is assumed to be held on the $31^{th}$ of May 1868 in Paris. Nowadays, after roughly 145 years, Cycling is one of the top 10 most popular sports during the Summer Olympics \cite{TopEndSportsUrl} and attracts millions of fans worldwide. Cycling competitions are divided into three main categories: \textit{road, track and off-road events}. Like in any popular sports, researchers showed their interest in strategies that could simulate the outcome of races. Efforts have been made to characterize as accurate as possible cycling races, and led to mathematical formulas taking into consideration almost all the physical [ from physics, like gravity, etc etc.. - need rephrase ? ] factors in a race. Some examples can be seen in \cite{AgentModel} or \cite{SlipStream} .

During our project, we have focused mainly on \textit{road events}: \textbf{road race, criterium, hill climbing and stage races} and Sprint \textit{track events}. For a novice watching those competitions, it might seem peculiar the way athletes compete with each other. Even though they are competing  with each other, their only chance of success is to team up with their competitors. This behaviour is mostly noted in the Stage Races like Tour de France or Tour de Faso.

In the following report we will focus on races where players are forced to cooperate and ask ourself  whether we can derive a game theory model that can model the optimal behaviour for a cyclist. We have created a simulation of a road race and aimed to make it as real as possible as a real life race (\textbf{Chapter ?}). In order to generate our needed functions, we had to use the Runge-Kutta method ( \textbf{Chapter ?} ) of estimating a function based on an initial value and it's derivatives. Due to the fact that the strategies used in the above mentioned races can be modelled using Game Theory, we have proposed a model that should cover the possible outcomes of a race ( \textbf{Chapter ?} ). We are also using the model in order to validate the results from the simulation.


\chapter{Design and Implementation}

As you can see from the Introduction, our project is split into 2 parts that are described below:

% Shouldn't that be in the Project Management section ?
Being a research project, after our initial meetings, we have divided into two small teams, one focued on implementing the simulation, and the other focusing on the mathematics for the Game Theory model.



\section{The software model}

The first part of our project was to create a software simulation of cycling races. For that we first considered reproducing a model described in \cite{AgentModel}. It seemed like a fairly easy task at first, but we ran into several complications.

\subsection{The first model}

In section 2 of \cite{AgentModel} is described an agent based model for cycling races. Each individual cyclist is represented by its physical and strategic attributes. The cyclists are themselves grouped into packs, any two cyclists that are within three meters of each others are in the same pack. To keep the model manageable, simplifications of the real world had to be made (physical as well as behavioural). In spite of those simplifications, the model still captures the principal elements of professional cycling. \\

The goal of packs is to use the slipstream effect cooperatively, taking turns in breaking the wind. Therefore in a pack cyclists rotate to the position of leader (which is more physically demanding), ideally each cyclist in the pack spend the same amount of time being the leader.

The strategies are defined probabilistically, each cyclist depends on two probabilities to make his decisions. These are distributed normally with mean 0.48 and distribution 0.21 with truncation at 0 and 1. The fist of these probability is the probability of the cyclist acting cooperatively towards his pack, i.e. whether or not he will breakaway and if he is the leader whether or not he will do his share in full. The second one is the probability of acting cooperatively towards your team, i.e. if one of his team mate breaks away, will he follow him. \\

During the race, the cyclists can therefore be in two different states, they are either part of a pack, or breaking away. When they are breaking away, they will stay in a breakaway state for three minutes before forming a new pack or joining an existing one.

In the last 5 kilometres of the race, the packs dissolves and each cyclists acts individually and starts sprinting. \\

The issue with this model however was with the description of how the cyclists get tired. It was unclear in the paper exactly how it was done, and there was no way of cumulating the energy used. We therefore looked at the description of a better exhaustion and performance model in another paper.

\subsection{The updated model}

We used the description of the physical model provided in \cite{MathModel} to update our previous simulation. It has a more precise description of the physical abilities of a cyclist, the motion being based on power output instead of speed, and of the effects of exhaustion. These are described bellow.

\subsubsection{Derivation of the differential equation for modelling the motion of a cyclist}

For the following equations we will use the next symbols: \\

\begin{tabularx}{\linewidth}{|c|X|}
\hline
P is power	&	\_pot is potential energy	\\
T is torque	&	\_air is air drag			\\
F is Force 	&  	\_bear is friction in the wheel bearings \\
			& 	\_roll is the rolling friction (with the road) \\
			& 	\_kin is kinetic energy \\
			&	\_ped is cyclist's 'input' (e.g. $P_{ped}$ = power input into the system) \\
\hline
\multicolumn{2}{|c|}
{
	$l_{c}$  is the length of the cycling crank and
	% maybe use a parbox here? http://tex.stackexchange.com/questions/485/how-to-break-a-line-in-a-table
	$r_{w}$  is the radius of the wheel
} \\
\hline
\end{tabularx}
\vspace{1cm}

$\eta$ 		represents the frictional losses in the drive chain \\
$\omega$ 	represents angular velocity.\\
$\gamma$	is the step-up coefficient the bicycles gearing system.  \\
\newpage
So by conservation of energy:

$$P_{pot} + P_{air} + P_{bear} + P_{roll} + P_{kin} = \eta * P_{ped}$$

As $Power = Torque * \omega$ , by dividing with $\omega$ we get

$$ T_{pot} + T_{air} + T_{bear} + T_{roll} + T_{kin} = \frac{ \eta * T_{ped} }{ \gamma }  = \frac{\eta * P_{ped}}{\omega * \gamma} $$

From the above notations have $T_{ped}$ = $F_{ped} * l_{c}$ (due to mechanical advantage) and $T = \frac{F * l_{c}}{r_{w}}$ for all the other forces (as there is a dual mechanical advantage between the crank and the wheel)

This gives us: $$ F_{pot} + F_{air} + F_{bear} + F_{roll} + F_{kin}
	= \frac{ \eta * l_{c} * T_{ped} }{ \gamma }
	= \frac{ \eta * l_{c} * P_{ped} }{ r_{w} * (\omega * \gamma)} $$

As we assume the race is on a perfectly flat surface, then $F_{pot} = 0$. We also assume that the bicycle is 'perfect', so $F_{bear} = 0$. \\\\
This simplifies to: $$F_{air} + F_{kin} = \frac{l_{c} * P_{ped} }{ \omega * \gamma } $$

where $$ F_{air} 	= \frac{1}{2} * c_{d} * \rho * A * ( x'(t) )^{2} $$
and	  $$ F_{kin} 	= ( m + ( \frac{l_w}{r_w^{2}} ) * x''(t) $$

Results from the Paper (...)\\

We are using the following estimates:

\begin{alltt}
mass of cyclist (m) 				= 63
frontal area of cyclist (A) 		= 0.75
length of crank (\(l_{c}\)) 		= 0.2
air density (\(\rho\)) 				= 1.225 (sea level, 15 degree Celsius)
drag coefficient of a cyclist (d) 	= 0.7
wheel inertia (\(I_w\)) = 0 (as perfect bicycle)
radius of wheel (\(r_w\)) = 0.35
step-up coefficient of gearing (\(\gamma\)) = 7.5
angular velocity of wheels (\(\omega\)) = \(2 * \pi * speed / {r_{w}} \)
\end{alltt}

Therefore the differential equation simplifies to:
$$ 0.3215625 * (x'(t))^{2} + 63 * x''(t)
	= \frac{\eta * l_{c} * P_{ped}} {2 * \pi * x'(t) * \gamma }
	= \frac {0.2 * P_{ped}} {15 * \pi} $$

Which gives approximation of:
$$ 75.7664 *(x'(t))^{3} + 14844.025288499999 * x'(t) * x''(t) = P_{ped}$$

which is a second order non-linear differential equation.\\\\

However this differential equation does not take into account the ``slipstream'' effect.

\subsubsection{Integrating the slipstream effect into the differential equation for modelling the motion of a cyclist.}

The slipstream effect is the effect by which the drag on an object moving through a fluid is diminished by the fact that the fluid it is moving through is already moving at a certain speed due to it being in the wake of another object in motion. \newline \par

This can be modelled for cyclists by applying a correction factor ($CF_{draft}$) to $P_{air}$ (which creates the same change in $F_{air}$) in the derivation of the differential equation that depends on the distance between a cyclist and the cyclist in front of him ($d_w$). \newline \par

If $d_w \ge 3$, then $C_{draft} = 1$ as the slipstream effect makes no difference over greater distances (the fluid in the wake of the object in front has the time to stop moving). \\
If $d_w < 3$, then $C_{draft} = 0.62 - 0.0104*d_w + 0.0452*d_w^2$ . $^{\cite{SlipStream}}$ \\
As in this figure:

\begin{figure}[!ht]
  \centering
    \input{plot.tex}
  \caption{plot of $CF_{draft}$ against $d_w$}
\end{figure}

Note that $CF_{draft} \approx 1$ at $d_w = 3$ on this graph. \\

Multiplying $F_{draft}$ by this correction factor gives the new differential equation:
$$ (0.62 - 0.0104*d_w + 0.0452*d_w^2) * 75.7664 *(x'(t))^{3} + 14844.025288499999 * x'(t) * x''(t) = P_{ped}$$

A second order differential equation that models our systems and takes into account the slipstream effect.

\subsubsection{An exhaustion model for cycling}

We add three new constants (all normally distributed) and one new variable to the definition of each cyclist to implement this model. The new constants are :
\begin{itemize}
\item $P_{max}$ : the maximum power output of a cyclist.
\item $P_{CP}$ : the maximum aerobic power output of a cyclist. (The highest speed at which the can cycle without ever getting tired)
\item $E_{an}$ : the maximum energy output from the cyclist anaerobic system before it must rest.
\end{itemize}
The new variable is $e_{an}$ : the amount of the anaerobic energy capacity that has already been consumed (initially $e_{an} = 0$). \\

The differential of $e_{an}$ depends on the difference between the cyclist maximum aerobic power output ($P_{CP}$) and his current power output ($P_{ped}$, set according to the psychological model), giving :
$$ e_{an}' = P_{ped} - P_{CP} $$

The values of $e_{an}$ are truncated such that $0 < e_{an} < E_{an}$. If at some point $e_{an}$ reaches $E_{an}$ the cyclist has to stop [add issues].

\subsection{The implementation}

\subsubsection{Runge-Kutta}

% Initial equations

Runge-Kutta is a standard numerical method that allows one to estimate a function based on an initial value and the function's differential. It is similar to the standard ``newton method" ($f(x + h) \approx f(x) + h*f'(x)$), but it uses several points inside a trapezium to trace the function significantly better. \\ % Runge-Kutta method is used in [ write more here... ]
\newline
full desc of runge-kutta.\\
\newline
This allows approximations to be made for functions for which we have a first order differential equation. It can also be used to approximate $n$ interdependent functions if it has an initial value for each and a differential that depends on the $n - 1$ other functions' values at $x$ and on $x$ itself.\\

So as above we have the differentials of $n$ functions denoted $y_1'(t),..,y_n'(t)$, which can each be written as: \\

{\centering $y_k'(t) = f_k(t,y_1(t),y_2(t),..,y_{(k-1)}(t),y_{(k+1)},..,y_n(t))$ \newline \par}

The each of the differentials can be given the current value of t and the $n - 1$ previous estimated values (initially the initial values) of the other function and then running Runge-Kutta with respect to t on each of them with a small h. \newline \par

This means that if we can transform our second order differential equation into a system of two first order coupled differential equations from which the information we want can be analytically derived, we can use the Runge-Kutta method to solve it numerically and then derive any necessary values from the result. \newline \par

In order to apply the Runge-Kutta algorithm, we need to transform it into two linear differential equations. We will define 2 independent variables, $y_1$ and $y_2$ such that their differentials $y_1'$ and $y_2'$ must depend on the variables t, $y_1$ and $y_2$. Let
$$ y_1' = f( t, y_1, y_2 )$$ and $$y_2' = g( t, y_1, y_2 )$$

In order to get x'(t) we want to set one of the equations to contain it: $y_1 = x'(t)$ and because we want one of the equations to contain $x'(t) * x''(t) $ so set: $y_2' = x'( t ) * x''( t )$ .
This gives us $$ y_{2} = \frac{1}{2} * x'(t)^2 $$
By rearranging the differential equation to have only $ x'( t ) * x''( t )$ on the left hand side, we get
$$ x'( t ) * x''( t ) = \frac{P_{ped} - 75.7665 * x'( t ) ^ 3}{14844.025288499999}$$
$$ y_2' = \frac{P_{ped} - 75.7665 * y_1 ^ 3}{14844.025288499999}$$

Now we have only $y_2'$ in terms of only t, $y_1$ and $y_2$ so we can set $$ g( t, y_1, y_2 ) = \frac{P_{ped} - 75.7665 * y_1 ^ 3}{14844.025288499999}$$

Writing $y_1$ in terms of t, $y_1$ and $y_2$: $$y_2 = \frac{1}{2} * x'(t)^2$$ yelds $$y_2 = \frac{1}{2} * y_1^2$$
And by rearranging the left hand side we get:
$$y_1 = \sqrt{2 * y_2}$$
Now we differentiate with respect to $t$:
\begin{align*}
y_1' & = \frac{y_2'}{\sqrt{2 * y_2}}\\
& = \frac{P_{ped} - 75.7665 * y_1 ^ 3}{14844.025288499999 * \sqrt{2 * y_2}}
\end{align*}
This gives us the final form for function f:
$$ f(t, y_1, y_2) = \frac{P_{ped} - 75.7665 * y_1 ^ 3}{14844.025288499999 * \sqrt{2 * y_2}}$$

To take the slipstream effect into account, we only have to make a relatively small modification (only the movement to the left hand side changes for $y_2'$ changes, adding a dependence on $d_w$):
$$ f(t, y_1, y_2) = \frac{P_{ped} - 75.7665 * (0.62 - 0.0104*d_w + 0.0452*d_w^2) * y_1 ^ 3}{14844.025288499999 * \sqrt{2 * y_2}}$$

$$ g( t, y_1, y_2 ) = \frac{P_{ped} - 75.7665 * (0.62 - 0.0104*d_w + 0.0452*d_w^2) * y_1 ^ 3}{14844.025288499999}$$ \\

$d_w$ can either be set to the initial value at the beginning of the minute or changed dynamically, but this requiers a simultaneous simulation of all the cyclists to see how they change in real time, which is quite complex.

% Game theoretical model introduction

\section{Game Theory model introduction}

In order to create a thorough mathematical model, we aim at constructing a game theoretical model. This model will help racers to change their strategies and choose the optimal one as the race unfolds.\\

Modelling bike races can be quite challenging, hence we will begin with the simplest case in order to introduce our methodology and explain the simplifying assumptions we are making. When participating in a race we can argue that racers are at each point faced with three possible options: breaking away from a group, fall back to group preceding the current one and cooperate with other members of the group (which essentially means to copy strategy of other players - which will be discussed later). Each of the racers can change his mind as often as he wants, however, changes in strategy will likely incur penalties on their performance. In this section we try to determine whether there is one dominant strategy and try to find at which point in race it is beneficial for racer to change his strategy. We can easily see that strategy chosen by players will depend on their skills and fitness, i.e. better racers can afford more aggressive, less cooperative strategy in hope of being able to outdistance opponents. On the other hand weaker players will tend to cooperate more. The difficulty of this part is not the actual solution to the model since it might happen there will not be a general solution but fitting the model to the actual situation. It is fairly easy to construct arbitrary game theoretical games, however, when the games have to even remotely represent reality they get complicated very quickly.\\

We start by discussion of case with two racers when the group chasing them is very far from them and does not affect the strategies. Thus, they are guaranteed to come first and second. We can clearly see that this is a zero-sum game since we can only gain place if our opponent loses one. We can argue that race is a zero-sum game in general regardless on number of players, however, we will leave discussion of this theory for later and we will see that the answer is not so obvious when we want to arrive at meaningful results. Since we have already concluded that this is the simplest of game theoretical models, we need to investigate actual pay off matrix for this game.

\subsection{Preliminaries}
Before we can dive into discussion of game theory can be used to approach bicycle racing problem we must introduce the terms we are making use of.

\paragraph{Breaking away} ~\\
We assume that when cyclist breaks away he does so with maximum possible speed. Hence, he is expending as much energy as possible.

\paragraph{Cooperation} ~\\
For a racer to cooperate means to follow the strategy of racers in the group. If there are more than two racers we assume that racers willing to cooperate will cooperate with breakaways and not stay in the group. When there are no breakaways cooperation will preserve current status of the game.

\paragraph{Fall back} ~\\
When a racer falls back he limits his velocity so that he will get caught by the group preceding the one he is part of at the moment of making decision. If there is no group to fall back to the racer moves to further position in the group. This action isn't instantaneous, however, we assume that racers will not form a group between falling back from one group to another.

\paragraph{Value Of A Game} ~\\
For a zero-sum game value of that game is the expected value to one of the players when both play a perfect strategy.

\paragraph{One-off Game} ~\\
This is a game played at some moment $\delta^{(n)}$ before race finish line which determines payoff at given moment.

\subsection{Zero sum game}
Let us consider the length of the race to be $R > 0$. In order to reason about the pay off of each player when choosing a certain strategy during the race, it is best to single out a moment when the choice of each player is clear. Hence, in the case we are currently discussing (two racers broke away from the chasing group and it is certain they cannot be caught), we easily realize that in the last $\delta\ km$, where $\delta\ll R$, the two players will definitely choose to breakaway and push as hard as possible in order to win the race. This will have pay off $C_i>0$ for player $i$, where $i \in \{1,2\}$.
\\\\
Let us now consider the moment $\delta'$, with $\delta'>\delta$ and $\delta'\ll R$. We can easily infer that the pay off for each player $i$ is $\max\{C_i,V_{\delta'_i}\}$, where $V_{\delta'_i}$ is the value of the one-off game at moment $\delta'$ for player $i$. By continuing in this manner we get that at moment $\delta^{(n)}$, with $\delta^{(j)}>\delta^{(i)}$ for all $j>i$ and $\delta^{(0)}=\delta$ we have that the pay off for each player $i$ is $P_{i,n} = \max\{P_{i,n-1},V_{\delta^{(n)}_i}\}$, where $P_{i,0} = C_i$. Hence, we have deduced a recursive relation that lets us easily reason about the choice of strategies.
\\\\
In order to get the one-off game pay-off matrices we need the following formulas:\\
$CS_{i,n} = \dfrac{P_{ped_{i,n}} \cdot \delta^{(n)}}{E_{i,n} \cdot v},\ i\in\{1,2\}$ - the interpretation of this coefficient is the proportion of energy we have to reach finish at given speed, calculated at moment $\delta^(n)$.\\
$CF_{draft}(x)=(0.62 - 0.0104d_w + 0.0452 d_w^2)\cdot (1/2)\cdot c_d\cdot \rho\cdot A\cdot x^2$ -  represents the force applied to the cyclist due to the aerodynamic drag from the air taking into account the slipstream effect. In this case the $x$ is the speed of the cyclist. We remind the reader that $d_w$ is the distance between the two cyclists.
$P = \dfrac{CS_{1,n}}{CS_{1,n}+CS_{2,n}}$ - the probability of player 1 being in front on player 2 at moment $\delta^{(n)}$ depending on their $CS_{i,n}$.
\\\\
We will list the possible strategy combinations with their respective pay-off players might use during the game. Before doing so, let us define $CF_{max}$ to be the maximum draft a player can attain, and $CF_{min}$ the minimum one.
\\\\
\textbf{Player 1 Cooperates, Player 2 Cooperates}
\\
The pay-off for Player 1 is $(1-P)\cdot CF_{draft}(s_1)$ and $P \cdot CF_{draft}(s_2)$ for Player 2, where $s_i$ is the speed of Player $i$. The pay-off for the two players is as such because if they cooperate they gain an advantage by drafting one behind the other ($CF_{draft}(s_i)$). This advantage, however, is greater for the player behind as he will put less effort, hence we need the probability $P$ of Player 1 having first place.
\\\\
We now need to normalize these quantities such that we get a pay-off in the interval [1,2], where 1 represents the worst pay-off (i.e. second place) and 1 the best (i.e. first place). After normalization we get that the pay-off for Player 1 is $(1-P)\cdot \dfrac{CF_{draft}(s_1)}{CF_{max}} + 1$ and the one for Player 2 is $P\cdot \dfrac{CF_{draft}(s_2)}{CF_{max}} + 1$.
\\\\
The reasoning behind the normalization is as follows:\\
Let us consider the pay-off for Player 1 (for Player 2 we reasoning is similar). Notice that is $P=1$, then the formula is 0. Let us multiply it by a normalization coefficient $N$ and add 1 to the formula. We get $(1-P)\cdot N\cdot CF_{draft}(s_1)  + 1$. Thus, if we replace $CF_{draft}(s_1)$ by $CF_{max}$, then this yields the following inequality: $(1-P)\cdot CF_{max} \cdot N + 1\le 2$. After several easy computations we get $N = \dfrac{1}{CF_{max}}$. Replacing it in the equation, we get the result. Note that the other inequality - $\ge 1$ - holds trivially.
\\\\
\textbf{Player 1 Cooperates, Player 2 Breaks-away}
\\
Player 1's pay-off is clearly the same as before, i.e. $(1-P)\cdot \dfrac{CF_{draft}(s_1)}{CF_{max}} + 1$ - after normalization. Because of the fact that Player 2 breaks-away then his pay-off depends on his positioning i.e. $1-P$, but we must also take into account whether or not he is trailing behind Player 1 and hence, if he can get any benefit from drafting. Thus, we have two disjoint probability events and we can argue that the pay-off is $(1-P) +  P\cdot \dfrac{CF_{draft}(s_2)}{CF_{max}} + 1$ - after normalization. To explain it a bit more, $P\cdot \dfrac{CF_{draft}(s_2)}{CF_{max}}$ this is the part of the pay-off that tells him the benefit he gets from drafting. We then want to specify that his pay-off also depends on the probability of him being in front and hence we add $1-P$. It is to remark the fact that we are still in the [1,2] interval as the events (trailing or leading) are disjoint.
\\\\
\textbf{Player 1 Cooperates, Player 2 Falls back}
\\
\textit{Note.} In this case by falling back, the reader should understand that Player 2 wants to trail behind Player 1 such that he can benefit from drafting. We have this interpretation because there is no chasing group that should be taken into account and thus, this is the only rational choice he can make.
\\\\
By the note above we conclude that the pay-off for the two players are $(1-P) +  P\cdot \dfrac{CF_{draft}(s_1)}{CF_{max}} + 1$ and $(1-P)\cdot \dfrac{CF_{draft}(s_2)}{CF_{max}} + 1$ for Player 1 and Player 2 respectively. Notice that the pay-offs are similar as in the situation above, only that they are swapped.
\\\\
\textbf{Player 1 Breaks-away, Player 2 Cooperates}
\\
Similar pay-off as in the case \textit{Player 1 Cooperates, Player 2 Breaks-away}. Only the order changes.
\\\\
\textbf{Player 1 Breaks-away, Player 2 Breaks-away}
\\
In this case both players stop cooperating and they depend solely on their performance which is computed by $P$ and $1-P$. Thus, we can argue that the pay-off for Player 1 is $P+1$ and the one for Player 2 is $2-P$, after normalization.
\\\\
\textbf{Player 1 Breaks-away, Player 2 Falls back}
\\
This is an interesting case, because Player 2 might play 'sneaky' and try to fall back and then benefit from drafting by chasing the player that broke away. However, we won't treat this situation because we want to preserve simplicity and because this case implies that Player 1 doesn't really manage to break-away. Thus, we conclude that the pay-off in this case is $P+1$ for Player 1 and 1 for Player 2.
\\\\
\textbf{Player 1 Falls back, Player 2 Cooperates}
\\
Similar pay-off as in the case \textit{Player 1 Cooperates, Player 2 Falls back}. Only the order changes.
\\\\
\textbf{Player 1 Falls back, Player 2 Breaks-away}
\\
Similar pay-off as in the case \textit{Player 1 Breaks-away, Player 2 Falls back}. Only the order changes.
\\\\
\textbf{Player 1 Falls back, Player 2 Falls back}
\\
In this case, we set both pay-offs to 1 (worst pay-off) because this strategy does not fully apply to our case.
\\\\
Now, we can trivially build a pay-off matrix containing the values we deduced above.\\\\
Pay-off of the game theoretical model resembles the rules outlined in [mention papers] after which our simulation has been created. We identified independent variables and made them influence pay-off values since this way we can generalise it to all types of players. Also it gives us basis for comparison which results will be shown later.\\\\
\textit{Note.} The reader may notice that we didn't specify the distance $d_w$. This should be varied in the simulation such that we can see which distance between the players is the optimal one for choosing certain strategies.

\subsection{Getting caught}
Everything seems fairly simple when there are only two racers competing. Entering realm of n-player games leaves us with few definite results as more interpersonal qualities come into play. It is an important to know that communication, players attitude towards each other and perceived strength of a player in a game can influence strategies chosen. However, we separate on case where we can get some results.
\\\\
For a case when two racers have escaped and are being chased by peloton we can consider scenarios when there exists a possibility of them being caught. It is no longer a zero-sum game since players can drop below $2^{nd}$ place and one can lose without other gain. However, we are not considering the chasing peloton as players. We are merely treating them as moving group of people that has a potential of catching up with the escape.
\\\\
First we need to quantify chance of being caught. Actually since we can know the distances between racers, their velocity and we can measure the time it is not only a possibility, but certainty. This holds as long as one of the groups does not change its strategy when we have to re-evaluate the chance. Consider $\epsilon \in \{0,1\}$, it has value of 0 if the escape group consisting of our players will not be caught and 1 otherwise. We set $\epsilon$ at moment $\delta^{(n)}$ to 1 if $\frac{x}{v_{draft}}=\frac{x+d}{v_{group}}$ has a solution in range $0\le x\le d$ where $d$ is distance from peloton to escape group, $v_{draft}$ and $v_{group}$ are velocities of second (drafting) racer in escape and peloton (chasing group) respectively. Knowing value of $\epsilon$ we can simplify our model to considering two cases: one when players will safely reach finish first and second when they will be absorbed by peloton. It is easy to notice that the first case has been mostly solved in previous section. It only needs few adjustments. Also it is not difficult to derive pay-offs for absorbed case since players are likely to get places depending on their fitness across whole race group (it clearly would not be the case if all racers were considered to be players and were allowed to choose strategies as racers will react differently when chasing tired racers from escape).
\\\\
When trying to deduce the pay-off matrix one can notice that this problem can be divided into two cases - depending on the value of $\epsilon$ - which will finally yield in two matrices. These matrices will be swapped during the game depending on the situation players face.
\\\\
\textbf{$\epsilon$ is zero}
\\
This case is one that it is easily dealt with considering the work we need in the previous section. By having $\epsilon = 0$, it means that we could ignore the group from the equation and the matrix pay-off is, hence, identical to the one we got before.
\\\\
\textbf{$\epsilon$ is one}
\\
This case is a bit more interesting, but it can be easily solved by adding some extra observations on top of the previous game theoretical model. Before doing so, we define some more formulas that will be used.\\
$CS_{race} = \sum\limits_{i=1}^{N} CS_i$, where $N$ is the number of players in the game. \\
The first observation is that in some cases normalization will take place on the interval $[1,N]$. This is because the two front-runners can become part of the pack.\\
The relevant situations are those when one of the two players decides to fall back - this time to the chasing group - or wants to break-away. We decided that the rest of the situations should be treated as in the case above, maybe with normalization on $[1,N]$ instead of $[1,2]$.\\\\
Thus, when one of the players falls back, then his pay-off becomes $\dfrac{CS_i}{CS_{race}}$ where $i\in\{1,2\}$. Of course now we need to normalize this quantity on $[1,N]$. As we are on the interval $[0,1]$, the immediate solution is multiplying by $N-1$ and adding 1. The pay-off we get is $ \dfrac{CS_i}{CS_{race}}\cdot (N-1) + 1$. The next question is, what will the other player do? If the strategy is fall back as well, then his pay-off is calculated in a similar manner. Otherwise, any strategy will have the pay-off of the break-away strategy described in the previous model.

\subsection{Repeated Game}
We can consider our methodology of finding pay-off for the whole game with alteration allowing for change of strategy in order to allow optimal value of the game. Evaluating our model this way enables us to answer questions of optimal strategies at given points in time.\\\\
In order to evaluate the games presented above, we reduced everything to solving 3 by 3 one-off games. After doing this, we plug the values into the recursive formula and we get the required value of the game.

\subsection{N-player Cooperative Game}
This is the field we have touched least on since Game Theory offers very little with respect to identification methodology of solving this cases. When there are more than 2 players most of the rationality taken from granted in 2 player zero-sum games no longer applies. However, we could try and reduce everything to 2 players games, even though the results might not be as exact. The idea is to average the performance of $N-1$ players in order to create a new player. We will make this new player compete with the $N$th player. Thus, we reduce this to a 2 player game.\\\\
The reader may notice that we need to apply N-player games when the front-runners from the previous sections get caught by the chasing group. Here would be a place where we can apply the aforementioned reasoning. Another idea is to transform this game into an LP problem and solve it using classic algorithms.
\\\\
%\cite{GameTheoryNonTechnical} is good
%\cite{GameTheoryApplications} is also good
%\cite{TheoryOfGames} is awesome


\chapter{Evaluation}

-- What did we manage to do ?

\chapter{Conclusion}

-- What have we learned ?

-- What could have been done differently ?

-- What could we do next ?

\chapter{Project Management}

-- How did we organise ? How did it work ?


% To add something to the bibliography, look for the "import into BibTex" thingy on google scholar, and add the stuff into refs.bib.
\bibliographystyle{plain}
\bibliography{refs}

\end{document}
