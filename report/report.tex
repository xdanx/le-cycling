\documentclass[10pt, a4paper]{report}

\title{Cycling simulation\\or\\\textit{When} to break away?}
\date{\today}
\author{Dan Demeter\and Robert Kruszewski\and Alexandru P\u{a}unoiu \and C\'esar Prout\'e \and Julian Sutherland}


%\setlength\parindent{0pt}
\usepackage{tabularx, alltt, amsmath, multirow, graphicx, url, graphics}
\usepackage[]{caption}

%Our Executive Summary
\renewcommand{\abstractname}{Executive Summary}

% Better looking chapters headings
\usepackage{titlesec}
\titleformat{\chapter}
  {\normalfont\LARGE\bfseries}{\thechapter}{1em}{}
\titlespacing*{\chapter}{0pt}{3.5ex plus 1ex minus .2ex}{2.3ex plus .2ex}


\begin{document}

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page

%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\LARGE Imperial College London}\\[1.5cm] % Name of your university/college
\textsc{\Large Department of Computing}\\[0.5cm] % Major heading such as course name
\textsc{\large}\\[0.5cm] % Minor heading such as course title

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
{ \huge \bfseries Cycling simulation\\or\\\vspace{0.4cm}\textit{When} to break away?}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]

%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Authors:}\\
Dan Demeter \\
Robert Kruszewski\\
Alexandru P\u{a}unoiu\\
C\'esar Prout\'e\\
Julian Sutherland
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Supervisor:} \\
Dr. Panos \textsc{Parpas} % Supervisor's Name
\end{flushright}
\end{minipage}\\[5cm]

% If you don't want a supervisor, uncomment the two lines below and remove the section above
%\Large \emph{Author:}\\
%John \textsc{Smith}\\[3cm] % Your name

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large \today}\\[3cm] % Date, change the \today to a set date if you want to be precise

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

%\includegraphics{Logo}\\[1cm] % Include a department/university logo - this will require the graphicx package

%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with white space
\end{titlepage}

%% Ending of title page

\tableofcontents

\begin{abstract}

%TODO: needs improvement
% César : I think it needs to be more about what we did rather than how cycling works.

During our Group Project we were charged with analysing cycling races, in particular trying to provide theoretical foundations for analysing their outcomes. Cycling races are amongst one of the most popular sports worldwide. Their history dates back to the
$18^{th}$ century being adopted and since then the types of races spanned substantially: from Track cycling on banks and velodromes,
Cycle-cross, Mountain bike races, one-day road race, criterion or time trial to professional races such as
Tour de France, Giro d'Italia or Vuelta a Espa\~na. Despite their large popularity and considerable financing attracted by large races there is no formal way of estimating outcome of a race not to mention choosing the right strategy. Even though racing does not seem like a sport involving . Cycling racers are extremely exhaustive for organism and right timing of effort is of paramount importance for winning. One example might be Andy Schleck's victory during one of 2011 Tour de France stage races. His escape 60 km before finish line had been perceived unimportant by other racers, however, it granted him almost 4 minute lead at finish.

Result of our work are two tools that can assist when analysing cycling races. First of them is agent based model, based on work done by \cite{AgentModel}, \cite{MathModel} and \cite{SlipStream}, which aims to approximate real races and allows for simulation of arbitrary scenarios. It approximates some physical and biological conditions in order to make computations feasible from current technology and knowledge point of view. Hence, the model is limited with respect to accuracy. Although limited, with development in computational power and expansion of our understanding of human physiology the model could be extended and allow increasing accuracy of predictions. Even though the agent based model is quite versatile it doesn't allow to extract strategy from it. Hence, alongside the aforementioned model we have also derived a simple game theoretical framework which can be used not only to predict result but also compute optimal strategy for racer. Deriving game theoretical model from real life scenario is not an easy task which has been shown by \cite{GameTheoryApplications} and \cite{GameTheoryNonTechnical}. The game theoretical model would be of more use when one would want to make on the spot decisions regarding his strategy.

What we have created during this project could invaluable decision making framework for coaches and racers equally. One could use game theoretical model to derive set of candidate strategies. Further the strategies can be evaluated using our agent based model to correct the inherent inaccuracy of game theory when approximating real life situations. We believe that with growth of computational power and better understanding of cycling races the results achieved from models similar to ours can become very accurate. However, better understanding of human psychology will be essential in order to solve general game theoretical model. Currently existing frameworks from Von Neumann–Morgenstern and Aumann-Maschler do not specify which coalition will dominate the others, they just specify conditions for dominating coalition to satisfy.

% During those professional races it is expected that a group of riders break away
% from the main group and cooperate with each other in order to gain advantage from the main group ( called peloton ). Riders in such a
% group are forced to cooperate with each other, even though their chances of winning are decreasing as more members join the break away
% group. Also, when a breakaway group is being formed, riders from the peloton have to decide whether to chase it down or remain where
% they are.

% From our point of view, all these decisions can be modelled by a Game Theory strategy. During our project, we have tried to find optimum strategies that can be applied to various cycling races. We have proposed a Game Theory model based on our research and an independent simulation used to verify our model. We continued the work of [ cite the papers here] and try to obtain a model that is as appropriate as real life cycling races. Using our simulation combined with the game theory model we believe that one should be able to simulate any Professional cycling race. Coaches and racers can use this data then to compare decisions taken  during the race. Our project aims to combine both Game Theory strategies with data from multiple simulated races in order to output 'optimal' decisions

\end{abstract}


\chapter{Introduction}\label{ch:intro}

The first cycling race is assumed to be held on the $31^{th}$ of May 1868 in Paris. Nowadays, after roughly 145 years, Cycling is one of the top 10 most popular sports during the Summer Olympics \cite{TopEndSportsUrl} and attracts millions of fans worldwide. Cycling competitions are divided into three main categories: \textit{road, track and off-road events}. Like in any popular sports, researchers showed their interest in strategies that could simulate the outcome of races. Efforts have been made to characterize as accurate as possible cycling races, and led to mathematical formulas taking into consideration almost all the physical [ from physics, like gravity, etc etc.. - need rephrase ? ] factors in a race. Some examples can be seen in \cite{AgentModel} or \cite{SlipStream} .

During our project, we have focused mainly on \textit{road events}: \textbf{road race, criterium, hill climbing and stage races} and Sprint \textit{track events}. For a novice watching those competitions, it might seem peculiar the way athletes compete with each other. Even though they are competing  with each other, their only chance of success is to team up with their competitors. This behaviour is mostly noted in the Stage Races like Tour de France or Tour de Faso.

In the following report we will focus on races where players are forced to cooperate and ask ourself  whether we can derive a game theory model that can model the optimal behaviour for a cyclist. We have created a simulation of a road race and aimed to make it as real as possible as a real life race described in section \ref{sec:softmodel}. Due to the fact that the strategies used in the above mentioned races can be modelled using Game Theory, we have proposed a model that should cover the possible outcomes of a race in section \ref{sec:gameth}. We are also using the model in order to validate the results from the simulation.


\chapter{Design and Implementation}\label{ch:design&impl}

As you can see from the Introduction, our project is split into 2 parts that are described below:

% Shouldn't that be in the Project Management section ?
Being a research project, after our initial meetings, we have divided into two small teams, one focued on implementing the simulation, and the other focusing on the mathematics for the Game Theory model.


\section{The Software Model}\label{sec:softmodel}

The first part of our project was to create a software simulation of cycling races. For that we first considered reproducing a model described in \cite{AgentModel}. It seemed like a fairly easy task at first, but we ran into several complications.

\subsection{The First Model}\label{subsec:model1}

In section 2 of \cite{AgentModel} is described an agent based model for cycling races. Each individual cyclist is represented by its physical and strategic attributes. The cyclists are themselves grouped into packs, any two cyclists that are within three meters of each others are in the same pack. To keep the model manageable, simplifications of the real world had to be made (physical as well as behavioural). In spite of those simplifications, the model still captures the principal elements of professional cycling. \\

The goal of packs is to use the slipstream effect cooperatively, taking turns in breaking the wind. Therefore in a pack cyclists rotate to the position of leader (which is more physically demanding), ideally each cyclist in the pack spend the same amount of time being the leader.

The strategies are defined probabilistically, each cyclist depends on two probabilities to make his decisions. These are distributed normally with mean 0.48 and distribution 0.21 with truncation at 0 and 1. The fist of these probability is the probability of the cyclist acting cooperatively towards his pack, i.e. whether or not he will breakaway and if he is the leader whether or not he will do his share in full. The second one is the probability of acting cooperatively towards your team, i.e. if one of his team mate breaks away, will he follow him. \\

During the race, the cyclists can therefore be in two different states, they are either part of a pack, or breaking away. When they are breaking away, they will stay in a breakaway state for three minutes before forming a new pack or joining an existing one.

In the last 5 kilometres of the race, the packs dissolves and each cyclists acts individually and starts sprinting. \\

The issue with this model however was with the description of how the cyclists get tired. It was unclear in the paper exactly how it was done, and there was no way of cumulating the energy used. We therefore looked at the description of a better exhaustion and performance model in another paper.

\subsection{The Updated Model}\label{subsec:updmodel}

We used the description of the physical model provided in \cite{MathModel} to update our previous simulation. It has a more precise description of the physical abilities of a cyclist, the motion being based on power output instead of speed, and of the effects of exhaustion. These are described bellow.

\subsubsection{Derivation of the differential equation for modelling the motion of a cyclist}

For the following equations we will use the next symbols: \\

\begin{tabularx}{\linewidth}{|c|X|}
\hline
P is power	&	\_pot is potential energy	\\
T is torque	&	\_air is air drag			\\
F is Force 	&  	\_bear is friction in the wheel bearings \\
			& 	\_roll is the rolling friction (with the road) \\
			& 	\_kin is kinetic energy \\
			&	\_ped is cyclist's 'input' (e.g. $P_{ped}$ = power input into the system) \\
\hline
\multicolumn{2}{|c|}
{
	$l_{c}$  is the length of the cycling crank and
	% maybe use a parbox here? http://tex.stackexchange.com/questions/485/how-to-break-a-line-in-a-table
	$r_{w}$  is the radius of the wheel
} \\
\hline
\end{tabularx}
\vspace{1cm}

$\eta$ 		represents the frictional losses in the drive chain \\
$\omega$ 	represents angular velocity.\\
$\gamma$	is the step-up coefficient the bicycles gearing system.  \\
\newpage
So by conservation of energy:

$$P_{pot} + P_{air} + P_{bear} + P_{roll} + P_{kin} = \eta * P_{ped}$$

As $Power = Torque * \omega$ , by dividing with $\omega$ we get

$$ T_{pot} + T_{air} + T_{bear} + T_{roll} + T_{kin} = \frac{ \eta * T_{ped} }{ \gamma }  = \frac{\eta * P_{ped}}{\omega * \gamma} $$

From the above notations have $T_{ped}$ = $F_{ped} * l_{c}$ (due to mechanical advantage) and $T = \frac{F * l_{c}}{r_{w}}$ for all the other forces (as there is a dual mechanical advantage between the crank and the wheel)

This gives us: $$ F_{pot} + F_{air} + F_{bear} + F_{roll} + F_{kin}
	= \frac{ \eta * l_{c} * T_{ped} }{ \gamma }
	= \frac{ \eta * l_{c} * P_{ped} }{ r_{w} * (\omega * \gamma)} $$

As we assume the race is on a perfectly flat surface, then $F_{pot} = 0$. We also assume that the bicycle is 'perfect', so $F_{bear} = 0$. \\\\
This simplifies to: $$F_{air} + F_{kin} = \frac{l_{c} * P_{ped} }{ \omega * \gamma } $$

where $$ F_{air} 	= \frac{1}{2} * c_{d} * \rho * A * ( x'(t) )^{2} $$
and	  $$ F_{kin} 	= ( m + ( \frac{l_w}{r_w^{2}} ) * x''(t) $$

Results from the Paper (...)\\

We are using the following estimates:

\begin{alltt}
mass of cyclist (m) 				= 63
frontal area of cyclist (A) 		= 0.75
length of crank (\(l_{c}\)) 		= 0.2
air density (\(\rho\)) 				= 1.225 (sea level, 15 degree Celsius)
drag coefficient of a cyclist (d) 	= 0.7
wheel inertia (\(I_w\)) = 0 (as perfect bicycle)
radius of wheel (\(r_w\)) = 0.35
step-up coefficient of gearing (\(\gamma\)) = 7.5
angular velocity of wheels (\(\omega\)) = \(2 * \pi * speed / {r_{w}} \)
\end{alltt}

Therefore the differential equation simplifies to:
$$ 0.3215625 * (x'(t))^{2} + 63 * x''(t)
	= \frac{\eta * l_{c} * P_{ped}} {2 * \pi * x'(t) * \gamma }
	= \frac {0.2 * P_{ped}} {15 * \pi} $$

Which gives approximation of:
$$ 75.7664 *(x'(t))^{3} + 14844.025288499999 * x'(t) * x''(t) = P_{ped}$$

which is a second order non-linear differential equation.\\\\

However this differential equation does not take into account the ``slipstream'' effect.

\subsubsection{Integrating the slipstream effect into the differential equation for modelling the motion of a cyclist.}

The slipstream effect is the effect by which the drag on an object moving through a fluid is diminished by the fact that the fluid it is moving through is already moving at a certain speed due to it being in the wake of another object in motion. \newline \par

This can be modelled for cyclists by applying a correction factor ($CF_{draft}$) to $P_{air}$ (which creates the same change in $F_{air}$) in the derivation of the differential equation that depends on the distance between a cyclist and the cyclist in front of him ($d_w$). \newline \par

If $d_w \ge 3$, then $C_{draft} = 1$ as the slipstream effect makes no difference over greater distances (the fluid in the wake of the object in front has the time to stop moving). \\
If $d_w < 3$, then $C_{draft} = 0.62 - 0.0104*d_w + 0.0452*d_w^2$ . $^{\cite{SlipStream}}$ \\
As in this figure:

\begin{figure}[!ht]
  \centering
    \input{plot.tex}
  \caption{plot of $CF_{draft}$ against $d_w$}
\end{figure}

Note that $CF_{draft} \approx 1$ at $d_w = 3$ on this graph. \\

Multiplying $F_{draft}$ by this correction factor gives the new differential equation:
$$ (0.62 - 0.0104*d_w + 0.0452*d_w^2) * 75.7664 *(x'(t))^{3} + 14844.025288499999 * x'(t) * x''(t) = P_{ped}$$

A second order differential equation that models our systems and takes into account the slipstream effect.

\subsubsection{An exhaustion model for cycling}

We add three new constants (all normally distributed) and one new variable to the definition of each cyclist to implement this model. The new constants are :
\begin{itemize}
\item $P_{max}$ : the maximum power output of a cyclist.
\item $P_{CP}$ : the maximum aerobic power output of a cyclist. (The highest speed at which the can cycle without ever getting tired)
\item $E_{an}$ : the maximum energy output from the cyclist anaerobic system before it must rest.
\end{itemize}
The new variable is $e_{an}$ : the amount of the anaerobic energy capacity that has already been consumed (initially $e_{an} = 0$). \\

The differential of $e_{an}$ depends on the difference between the cyclist maximum aerobic power output ($P_{CP}$) and his current power output ($P_{ped}$, set according to the psychological model), giving :
$$ e_{an}' = P_{ped} - P_{CP} $$

The values of $e_{an}$ are truncated such that $0 < e_{an} < E_{an}$. If at some point $e_{an}$ reaches $E_{an}$ the cyclist has to stop [add issues].

\subsection{The implementation}\label{subsec:impl}

\subsubsection{Runge-Kutta}

% Initial equations

Runge-Kutta is a standard numerical method that allows one to estimate a function based on an initial value and the function's differential. It is similar to the standard ``newton method" ($f(x + h) \approx f(x) + h*f'(x)$), but it uses several points inside a trapezium to trace the function significantly better. \\ % Runge-Kutta method is used in [ write more here... ]
\newline
full desc of runge-kutta.\\
\newline
This allows approximations to be made for functions for which we have a first order differential equation. It can also be used to approximate $n$ interdependent functions if it has an initial value for each and a differential that depends on the $n - 1$ other functions' values at $x$ and on $x$ itself.\\

So as above we have the differentials of $n$ functions denoted $y_1'(t),..,y_n'(t)$, which can each be written as: \\

{\centering $y_k'(t) = f_k(t,y_1(t),y_2(t),..,y_{(k-1)}(t),y_{(k+1)},..,y_n(t))$ \newline \par}

The each of the differentials can be given the current value of t and the $n - 1$ previous estimated values (initially the initial values) of the other function and then running Runge-Kutta with respect to t on each of them with a small h. \newline \par

This means that if we can transform our second order differential equation into a system of two first order coupled differential equations from which the information we want can be analytically derived, we can use the Runge-Kutta method to solve it numerically and then derive any necessary values from the result. \newline \par

In order to apply the Runge-Kutta algorithm, we need to transform it into two linear differential equations. We will define 2 independent variables, $y_1$ and $y_2$ such that their differentials $y_1'$ and $y_2'$ must depend on the variables t, $y_1$ and $y_2$. Let
$$ y_1' = f( t, y_1, y_2 )$$ and $$y_2' = g( t, y_1, y_2 )$$

In order to get x'(t) we want to set one of the equations to contain it: $y_1 = x'(t)$ and because we want one of the equations to contain $x'(t) * x''(t) $ so set: $y_2' = x'( t ) * x''( t )$ .
This gives us $$ y_{2} = \frac{1}{2} * x'(t)^2 $$
By rearranging the differential equation to have only $ x'( t ) * x''( t )$ on the left hand side, we get
$$ x'( t ) * x''( t ) = \frac{P_{ped} - 75.7665 * x'( t ) ^ 3}{14844.025288499999}$$
$$ y_2' = \frac{P_{ped} - 75.7665 * y_1 ^ 3}{14844.025288499999}$$

Now we have only $y_2'$ in terms of only t, $y_1$ and $y_2$ so we can set $$ g( t, y_1, y_2 ) = \frac{P_{ped} - 75.7665 * y_1 ^ 3}{14844.025288499999}$$

Writing $y_1$ in terms of t, $y_1$ and $y_2$: $$y_2 = \frac{1}{2} * x'(t)^2$$ yelds $$y_2 = \frac{1}{2} * y_1^2$$
And by rearranging the left hand side we get:
$$y_1 = \sqrt{2 * y_2}$$
Now we differentiate with respect to $t$:
\begin{align*}
y_1' & = \frac{y_2'}{\sqrt{2 * y_2}}\\
& = \frac{P_{ped} - 75.7665 * y_1 ^ 3}{14844.025288499999 * \sqrt{2 * y_2}}
\end{align*}
This gives us the final form for function f:
$$ f(t, y_1, y_2) = \frac{P_{ped} - 75.7665 * y_1 ^ 3}{14844.025288499999 * \sqrt{2 * y_2}}$$

To take the slipstream effect into account, we only have to make a relatively small modification (only the movement to the left hand side changes for $y_2'$ changes, adding a dependence on $d_w$):
$$ f(t, y_1, y_2) = \frac{P_{ped} - 75.7665 * (0.62 - 0.0104*d_w + 0.0452*d_w^2) * y_1 ^ 3}{14844.025288499999 * \sqrt{2 * y_2}}$$

$$ g( t, y_1, y_2 ) = \frac{P_{ped} - 75.7665 * (0.62 - 0.0104*d_w + 0.0452*d_w^2) * y_1 ^ 3}{14844.025288499999}$$ \\

$d_w$ can either be set to the initial value at the beginning of the minute or changed dynamically, but this requiers a simultaneous simulation of all the cyclists to see how they change in real time, which is quite complex.

% Game theoretical model introduction

\section{Game Theory Model}\label{sec:gameth}

In order to create a thorough mathematical model, we aim at constructing a game theoretical model. This model will help racers to change their strategies and choose the optimal one as the race unfolds.\\

Modelling bike races can be quite challenging, hence we will begin with the simplest case in order to introduce our methodology and explain the simplifying assumptions we are making. When participating in a race we can argue that racers are at each point faced with three possible options: breaking away from a group, fall back to group preceding the current one and cooperate with other members of the group (which essentially means to copy strategy of other players - which will be discussed later). Each of the racers can change his mind as often as he wants, however, changes in strategy will likely incur penalties on their performance. In this section we try to determine whether there is one dominant strategy and try to find at which point in race it is beneficial for racer to change his strategy. We can easily see that strategy chosen by players will depend on their skills and fitness, i.e. better racers can afford more aggressive, less cooperative strategy in hope of being able to outdistance opponents. On the other hand weaker players will tend to cooperate more. The difficulty of this part is not the actual solution to the model since it might happen there will not be a general solution but fitting the model to the actual situation. It is fairly easy to construct arbitrary game theoretical games, however, when the games have to even remotely represent reality they get complicated very quickly.\\

We start by discussion of case with two racers when the group chasing them is very far from them and does not affect the strategies. Thus, they are guaranteed to come first and second. We can clearly see that this is a zero-sum game since we can only gain place if our opponent loses one. We can argue that race is a zero-sum game in general regardless on number of players, however, we will leave discussion of this theory for later and we will see that the answer is not so obvious when we want to arrive at meaningful results. Since we have already concluded that this is the simplest of game theoretical models, we need to investigate actual pay off matrix for this game.


\subsection{Definitions}\label{subsec:defs}

Before we can dive into discussion of game theory can be used to approach bicycle racing problem we must introduce the terms we are making use of.

\paragraph{2-person Zero-sum Game} ~\\
Two-person zero-sum game describes conflict of interest between two players with strictly opposite interests. Formally this means that any change in the pay-off of one player has to be offset with equal decrease in amount of payout to the second player. These types of games can be divided into three subsections depending on the achievable results to the game. We can have a dominant strategy equilibrium, pure strategy Nash equilibrium and mixed strategy Nash equilibrium each with less strictness imposed on the result.
\subparagraph{Dominant Strategy Equilibrium}
is represented by table below. Ease of analysing such games stems from the fact that there is always a clear strategy that a player has to follow in order to achieve maximum payout.
\begin{table}[ht!]
	\hspace{-4em}
	\centering
	\begin{tabular}{ccccc|}
		& & \multicolumn{3}{c}{Player1}                                \\ \cline{3-5}
		& & A & B & \multicolumn{1}{c}{C}                              \\ \cline{3-5}
		\multirow{3}{*}{Player2} & \multicolumn{1}{|c|}{a} & 2 & 1 & 7 \\
		& \multicolumn{1}{|c|}{b} & 4 & 5 & 6                          \\
		& \multicolumn{1}{|c|}{c} & 3 & 1 & 7                          \\ \cline{3-5}
	\end{tabular}
	\caption{2-person zero-sum game\\ dominant strategy equilibrium}
\end{table}
\\
In case of above matrix one can deduce that dominant strategy is (A,b).

\subparagraph{Pure Nash Strategy Equilibrium} represents a situation when no player has an incentive to deviate from the strategy chosen, since no player can choose a better strategy given the choices of the other players. Consider following table.
\begin{table}[ht!]
	\hspace{-4em}
	\centering
	\begin{tabular}{ccccc|c}
		& & \multicolumn{3}{c}{Player1} &                                     \\ \cline{3-5}
		& & A & B & \multicolumn{1}{c}{C} & min                               \\ \cline{3-5}
		\multirow{3}{*}{Player2} & \multicolumn{1}{|c|}{a} & 11 & -7 & 8 & -7 \\
		& \multicolumn{1}{|c|}{b} & 1 & 1 & 2 & 1                             \\
		& \multicolumn{1}{|c|}{c} & -10 & -7 & 21 & -10                       \\ \cline{3-5}
		& max & 11 & 1 & \multicolumn{1}{c}{21} &
	\end{tabular}
	\caption{2-person zero-sum game\\ pure strategy Nash equilibrium}
\end{table}
\\
In case of above matrix one can deduce that Nash equilibrium is at (B,b) since no player can do any better taking into account his opponents strategy.

\subparagraph{Mixed Strategy Nash Equilibrium} is a situation when there is no pure strategy, hence we cannot state that one strategy is better than the other always. However, we can still obtain a solution to this game by assigning probabilities to strategies. By playing strategies according to their corresponding probabilities one can achieve optimal expected output of the game. Following table show situation like this
\begin{table}[ht!]
	\hspace{-2em}
	\centering
	\begin{tabular}{ccccc|c}
		& & \multicolumn{3}{c}{Player1} &                                  \\ \cline{3-5}
		& & A & B & \multicolumn{1}{c}{C} & min                            \\ \cline{3-5}
		\multirow{3}{*}{Player2} & \multicolumn{1}{|c|}{a} & 0 & 0 & 8 & 0 \\
		& \multicolumn{1}{|c|}{b} & -1 & 1 & 2 & -1                        \\
		& \multicolumn{1}{|c|}{c} & -10 & -7 & 21 & -10                    \\ \cline{3-5}
		& max & -1 & 1 & \multicolumn{1}{c}{21} &
	\end{tabular}
	\caption{2-person zero-sum game\\mixed strategy Nash equilibrium}
\end{table}
\\
There is no equilibrium strategy, however, on can be found using Linear Programming techniques.

\paragraph{2-person Non Zero-sum Game} ~\\
Non zero-sum game turn out to be considerably more difficult to analyse properly. Even tough we are usually able to find optimal strategy it might not be the best strategy. Furthermore when game is played more than once, strategy presumed to be optimal in single case might not be the most effective one. The most famous example of such game is the Prisoner's Dilemma. Albert W. Tucker formalised this problem giving it its name:
\begin{quotation}
    Two members of a criminal gang are arrested and imprisoned. Each prisoner is in solitary confinement with no means of speaking to or exchanging messages with the other. The police admit they don't have enough evidence to convict the pair on the principal charge. They plan to sentence both to a year in prison on a lesser charge. Simultaneously, the police offer each prisoner a Faustian bargain. If he testifies against his partner, he will go free while the partner will get three years in prison on the main charge. Oh, yes, there is a catch ... If both prisoners testify against each other, both will be sentenced to two years in jail.
\end{quotation}
Above description can be represented by pay-off matrix like this:
\begin{table}[ht!]
	\hspace{-2em}
	\centering
	\begin{tabular}{cccc|}
		& & \multicolumn{2}{c}{Player 2}                                              \\ \cline{3-4}
		& & Stay Silent &  \multicolumn{1}{c}{Testify}                                \\ \cline{3-4}
		\multirow{2}{*}{Player 1} & \multicolumn{1}{|c|}{Stay Silent} & (1,1) & (0,3) \\
		& \multicolumn{1}{|c|}{Testify} & (3,0) & (2,2)                               \\ \cline{3-4}
	\end{tabular}
	\caption{Prisoner's Dilemma pay-off matrix}
\end{table}
\\
We will leave it to the reader to find optimal strategy for this game as it turns out to be quite rewarding task. One can also consider whether his or hers strategy will be the same if the game was to be played more than once.

\paragraph{N-person Game} ~\\
Considering N-person games leaves much to be desired from. One of the problems is that possible strategies can grow exponentially with number of players, hence, these problems are at least more computationally difficult than 2-person games. Also when a player is faced with more than one equivalent, however, differing in terms of pay-off option will not always choose the strategy guaranteeing highest pay-off. Furthermore interpersonal factors come into play and are of great significance and players need to carefully consider what inducements they must offer and accept. In our work we do not consider pure N-person games, however, we present how with respect to cycling races such cases can be simplified with some level of accuracy.

For deeper and more detailed explanation reader is encouraged to make himself familiar with contents of "Game theory : a nontechnical introduction"\cite{GameTheoryNonTechnical} or "Games, theory and applications"\cite{GameTheoryApplications}. Further in the work we assume that reader is at least familiar with the concepts presented above.

\paragraph{Breaking away} ~\\
We assume that when cyclist breaks away he does so with maximum possible speed. Hence, he is expending as much energy as possible.

\paragraph{Cooperation} ~\\
For a racer to cooperate means to follow the strategy of racers in the group. If there are more than two racers we assume that racers willing to cooperate will cooperate with breakaways and not stay in the group. When there are no breakaways cooperation will preserve current status of the game.

\paragraph{Fall back} ~\\
When a racer falls back he limits his velocity so that he will get caught by the group preceding the one he is part of at the moment of making decision. If there is no group to fall back to the racer moves to further position in the group. This action isn't instantaneous, however, we assume that racers will not form a group between falling back from one group to another.

\paragraph{Value Of A Game} ~\\
For a zero-sum game value of that game is the expected value to one of the players when both play a perfect strategy.

\paragraph{One-off Game} ~\\
This is a game played at some moment $\delta^{(n)}$ before race finish line which determines payoff at given moment.

\subsection{2-racer Escape Case}\label{subsec:zerosumgame}
Let us consider the length of the race to be $R > 0$. In order to reason about the pay off of each player when choosing a certain strategy during the race, it is best to single out a moment when the choice of each player is clear. Hence, in the case we are currently discussing (two racers broke away from the chasing group and it is certain they cannot be caught), we easily realize that in the last $\delta\ km$, where $\delta\ll R$, the two players will definitely choose to breakaway and push as hard as possible in order to win the race. This will have pay off $C_i>0$ for player $i$, where $i \in \{1,2\}$.
\\\\
Let us now consider the moment $\delta'$, with $\delta'>\delta$ and $\delta'\ll R$. We can easily infer that the pay off for each player $i$ is $\max\{C_i,V_{\delta'_i}\}$, where $V_{\delta'_i}$ is the value of the one-off game at moment $\delta'$ for player $i$. By continuing in this manner we get that at moment $\delta^{(n)}$, with $\delta^{(j)}>\delta^{(i)}$ for all $j>i$ and $\delta^{(0)}=\delta$ we have that the pay off for each player $i$ is $P_{i,n} = \max\{P_{i,n-1},V_{\delta^{(n)}_i}\}$, where $P_{i,0} = C_i$. Hence, we have deduced a recursive relation that lets us easily reason about the choice of strategies.
\\\\
In order to get the one-off game pay-off matrices we need the following formulas:\\
$CS_{i,n} = \dfrac{P_{ped_{i,n}} \cdot \delta^{(n)}}{E_{i,n} \cdot v},\ i\in\{1,2\}$ - the interpretation of this coefficient is the proportion of energy we have to reach finish at given speed, calculated at moment $\delta^(n)$.\\
$CF_{draft}(x)=(0.62 - 0.0104d_w + 0.0452 d_w^2)\cdot (1/2)\cdot c_d\cdot \rho\cdot A\cdot x^2$ -  represents the force applied to the cyclist due to the aerodynamic drag from the air taking into account the slipstream effect. In this case the $x$ is the speed of the cyclist. We remind the reader that $d_w$ is the distance between the two cyclists.
$P = \dfrac{CS_{1,n}}{CS_{1,n}+CS_{2,n}}$ - the probability of player 1 being in front on player 2 at moment $\delta^{(n)}$ depending on their $CS_{i,n}$.
\\\\
We will list the possible strategy combinations with their respective pay-off players might use during the game. Before doing so, let us define $CF_{max}$ to be the maximum draft a player can attain, and $CF_{min}$ the minimum one.
\\\\
\textbf{Player 1 Cooperates, Player 2 Cooperates}
\\
The pay-off for Player 1 is $(1-P)\cdot CF_{draft}(s_1)$ and $P \cdot CF_{draft}(s_2)$ for Player 2, where $s_i$ is the speed of Player $i$. The pay-off for the two players is as such because if they cooperate they gain an advantage by drafting one behind the other ($CF_{draft}(s_i)$). This advantage, however, is greater for the player behind as he will put less effort, hence we need the probability $P$ of Player 1 having first place.
\\\\
We now need to normalize these quantities such that we get a pay-off in the interval [1,2], where 1 represents the worst pay-off (i.e. second place) and 1 the best (i.e. first place). After normalization we get that the pay-off for Player 1 is $(1-P)\cdot \dfrac{CF_{draft}(s_1)}{CF_{max}} + 1$ and the one for Player 2 is $P\cdot \dfrac{CF_{draft}(s_2)}{CF_{max}} + 1$.
\\\\
The reasoning behind the normalization is as follows:\\
Let us consider the pay-off for Player 1 (for Player 2 we reasoning is similar). Notice that is $P=1$, then the formula is 0. Let us multiply it by a normalization coefficient $N$ and add 1 to the formula. We get $(1-P)\cdot N\cdot CF_{draft}(s_1)  + 1$. Thus, if we replace $CF_{draft}(s_1)$ by $CF_{max}$, then this yields the following inequality: $(1-P)\cdot CF_{max} \cdot N + 1\le 2$. After several easy computations we get $N = \dfrac{1}{CF_{max}}$. Replacing it in the equation, we get the result. Note that the other inequality - $\ge 1$ - holds trivially.
\\\\
\textbf{Player 1 Cooperates, Player 2 Breaks-away}
\\
Player 1's pay-off is clearly the same as before, i.e. $(1-P)\cdot \dfrac{CF_{draft}(s_1)}{CF_{max}} + 1$ - after normalization. Because of the fact that Player 2 breaks-away then his pay-off depends on his positioning i.e. $1-P$, but we must also take into account whether or not he is trailing behind Player 1 and hence, if he can get any benefit from drafting. Thus, we have two disjoint probability events and we can argue that the pay-off is $(1-P) +  P\cdot \dfrac{CF_{draft}(s_2)}{CF_{max}} + 1$ - after normalization. To explain it a bit more, $P\cdot \dfrac{CF_{draft}(s_2)}{CF_{max}}$ this is the part of the pay-off that tells him the benefit he gets from drafting. We then want to specify that his pay-off also depends on the probability of him being in front and hence we add $1-P$. It is to remark the fact that we are still in the [1,2] interval as the events (trailing or leading) are disjoint.
\\\\
\textbf{Player 1 Cooperates, Player 2 Falls back}
\\
\textit{Note.} In this case by falling back, the reader should understand that Player 2 wants to trail behind Player 1 such that he can benefit from drafting. We have this interpretation because there is no chasing group that should be taken into account and thus, this is the only rational choice he can make.
\\\\
By the note above we conclude that the pay-off for the two players are $(1-P) +  P\cdot \dfrac{CF_{draft}(s_1)}{CF_{max}} + 1$ and $(1-P)\cdot \dfrac{CF_{draft}(s_2)}{CF_{max}} + 1$ for Player 1 and Player 2 respectively. Notice that the pay-offs are similar as in the situation above, only that they are swapped.
\\\\
\textbf{Player 1 Breaks-away, Player 2 Cooperates}
\\
Similar pay-off as in the case \textit{Player 1 Cooperates, Player 2 Breaks-away}. Only the order changes.
\\\\
\textbf{Player 1 Breaks-away, Player 2 Breaks-away}
\\
In this case both players stop cooperating and they depend solely on their performance which is computed by $P$ and $1-P$. Thus, we can argue that the pay-off for Player 1 is $P+1$ and the one for Player 2 is $2-P$, after normalization.
\\\\
\textbf{Player 1 Breaks-away, Player 2 Falls back}
\\
This is an interesting case, because Player 2 might play 'sneaky' and try to fall back and then benefit from drafting by chasing the player that broke away. However, we won't treat this situation because we want to preserve simplicity and because this case implies that Player 1 doesn't really manage to break-away. Thus, we conclude that the pay-off in this case is $P+1$ for Player 1 and 1 for Player 2.
\\\\
\textbf{Player 1 Falls back, Player 2 Cooperates}
\\
Similar pay-off as in the case \textit{Player 1 Cooperates, Player 2 Falls back}. Only the order changes.
\\\\
\textbf{Player 1 Falls back, Player 2 Breaks-away}
\\
Similar pay-off as in the case \textit{Player 1 Breaks-away, Player 2 Falls back}. Only the order changes.
\\\\
\textbf{Player 1 Falls back, Player 2 Falls back}
\\
In this case, we set both pay-offs to 1 (worst pay-off) because this strategy does not fully apply to our case.
\\\\
Now, we can trivially build a pay-off matrix containing the values we deduced above.\\\\
Pay-off of the game theoretical model resembles the rules outlined in [mention papers] after which our simulation has been created. We identified independent variables and made them influence pay-off values since this way we can generalise it to all types of players. Also it gives us basis for comparison which results will be shown later.\\\\
\textit{Note.} The reader may notice that we didn't specify the distance $d_w$. This should be varied in the simulation such that we can see which distance between the players is the optimal one for choosing certain strategies.

\subsection{Getting caught}\label{subsec:getcaught}
Everything seems fairly simple when there are only two racers competing. Entering realm of n-player games leaves us with few definite results as more interpersonal qualities come into play. It is an important to know that communication, players attitude towards each other and perceived strength of a player in a game can influence strategies chosen. However, we separate on case where we can get some results.
\\\\
For a case when two racers have escaped and are being chased by peloton we can consider scenarios when there exists a possibility of them being caught. It is no longer a zero-sum game since players can drop below $2^{nd}$ place and one can lose without other gain. However, we are not considering the chasing peloton as players. We are merely treating them as moving group of people that has a potential of catching up with the escape.
\\\\
First we need to quantify chance of being caught. Actually since we can know the distances between racers, their velocity and we can measure the time it is not only a possibility, but certainty. This holds as long as one of the groups does not change its strategy when we have to re-evaluate the chance. Consider $\epsilon \in \{0,1\}$, it has value of 0 if the escape group consisting of our players will not be caught and 1 otherwise. We set $\epsilon$ at moment $\delta^{(n)}$ to 1 if $\frac{x}{v_{draft}}=\frac{x+d}{v_{group}}$ has a solution in range $0\le x\le d$ where $d$ is distance from peloton to escape group, $v_{draft}$ and $v_{group}$ are velocities of second (drafting) racer in escape and peloton (chasing group) respectively. Knowing value of $\epsilon$ we can simplify our model to considering two cases: one when players will safely reach finish first and second when they will be absorbed by peloton. It is easy to notice that the first case has been mostly solved in previous section. It only needs few adjustments. Also it is not difficult to derive pay-offs for absorbed case since players are likely to get places depending on their fitness across whole race group (it clearly would not be the case if all racers were considered to be players and were allowed to choose strategies as racers will react differently when chasing tired racers from escape).
\\\\
When trying to deduce the pay-off matrix one can notice that this problem can be divided into two cases - depending on the value of $\epsilon$ - which will finally yield in two matrices. These matrices will be swapped during the game depending on the situation players face.
\\\\
\textbf{$\epsilon$ is zero}
\\
This case is one that it is easily dealt with considering the work we need in the previous section. By having $\epsilon = 0$, it means that we could ignore the group from the equation and the matrix pay-off is, hence, identical to the one we got before.
\\\\
\textbf{$\epsilon$ is one}
\\
This case is a bit more interesting, but it can be easily solved by adding some extra observations on top of the previous game theoretical model. Before doing so, we define some more formulas that will be used.\\
$CS_{race} = \sum\limits_{i=1}^{N} CS_i$, where $N$ is the number of players in the game. \\
The first observation is that in some cases normalization will take place on the interval $[1,N]$. This is because the two front-runners can become part of the pack.\\
The relevant situations are those when one of the two players decides to fall back - this time to the chasing group - or wants to break-away. We decided that the rest of the situations should be treated as in the case above, maybe with normalization on $[1,N]$ instead of $[1,2]$.\\\\
Thus, when one of the players falls back, then his pay-off becomes $\dfrac{CS_i}{CS_{race}}$ where $i\in\{1,2\}$. Of course now we need to normalize this quantity on $[1,N]$. As we are on the interval $[0,1]$, the immediate solution is multiplying by $N-1$ and adding 1. The pay-off we get is $ \dfrac{CS_i}{CS_{race}}\cdot (N-1) + 1$. The next question is, what will the other player do? If the strategy is fall back as well, then his pay-off is calculated in a similar manner. Otherwise, any strategy will have the pay-off of the break-away strategy described in the previous model.

\subsection{Repeated Game}\label{subsec:repgame}
We can consider our methodology of finding pay-off for the whole game with alteration allowing for change of strategy in order to allow optimal value of the game. Evaluating our model this way enables us to answer questions of optimal strategies at given points in time.\\\\
In order to evaluate the games presented above, we reduced everything to solving 3 by 3 one-off games. After doing this, we plug the values into the recursive formula and we get the required value of the game.

\subsection{N-player Cooperative Game}\label{nplaycoopgame}
This is the field we have touched least on since Game Theory offers very little with respect to identification methodology of solving this cases. When there are more than 2 players most of the rationality taken from granted in 2 player zero-sum games no longer applies. However, we could try and reduce everything to 2 players games, even though the results might not be as exact. The idea is to average the performance of $N-1$ players in order to create a new player. We will make this new player compete with the $N$th player. Thus, we reduce this to a 2 player game.\\\\
The reader may notice that we need to apply N-player games when the front-runners from the previous sections get caught by the chasing group. Here would be a place where we can apply the aforementioned reasoning. Another idea is to transform this game into an LP problem and solve it using classic algorithms.
\\\\
%\cite{GameTheoryNonTechnical} is good
%\cite{GameTheoryApplications} is also good
%\cite{TheoryOfGames} is awesome


\chapter{Evaluation}\label{ch:eval}

-- What did we manage to do ?

\chapter{Conclusion}\label{ch:concl}

-- What have we learned ?

-- What could have been done differently ?

-- What could we do next ?

\chapter{Project Management}\label{ch:projmanag}

As our project consisted of two parts very different in nature, we divided the work between two subgroups. Julian Sutherland and C\'{e}sar Prout\'{e} worked on creating the software simulation, and Alexandru P\u{a}unoiu, Dan Demeter and Robert Kruszewski worked on the game theoretical model. We held weekly meetings with our supervisor(s?), to asses the work of the previous week and fix the goals for the next one. We also met together regularly to keep everyone updated on the general progress of the work and to make decisions. \\

In the simulation team, we worked closely together during the whole duration of the project. We made sure both of us agreed on the design decisions before writing any code. We usually worked together on the same part of the code or divided the work into small individual tasks. \\

[How the game theory worked] \\

Despite our attempt to have a productive and dynnamic organisation, our different obligations for other courses and work applications made the communication between people working on different parts of the project difficult sometimes, resulting in problems being unresolved for an unnecessary amount of time and leading ultimatelly to not being able to achieve all the goals we set for our project. \\


% To add something to the bibliography, look for the "import into BibTex" thingy on google scholar, and add the stuff into refs.bib.
\bibliographystyle{plain}
\bibliography{refs}

\end{document}
